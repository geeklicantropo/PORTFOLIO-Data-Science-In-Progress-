{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d5a880",
   "metadata": {},
   "source": [
    "<h1>A second model</h1>\n",
    "<p>After creating a initial model that fits the baseline, we want to create another model to beat the baseline.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ba378",
   "metadata": {},
   "source": [
    "<h5>Importing the libraries</h5>\n",
    "<p>Just like before, we are importing the libraries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd20b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import bs4 as bs4\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "pd.set_option(\"max.columns\", 131)\n",
    "\n",
    "#https://strftime.org/\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1868f1",
   "metadata": {},
   "source": [
    "<p>We are reading the CSV file and another non null column was created and named \"y\". That's our target variable.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba49425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_data_with_labels.csv\", index_col=0)\n",
    "df = df[df['y'].notnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1c47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = pd.DataFrame(index=df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b3235",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning</h1>\n",
    "<p>Same as before. No changes here.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fdde8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f64cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date[0] = clean_date[0].map(lambda x: \"0\"+x[0] if len(x) == 1 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d297e97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      03\n",
       "1      16\n",
       "2      02\n",
       "3      13\n",
       "4      30\n",
       "       ..\n",
       "496    01\n",
       "497    31\n",
       "498    10\n",
       "499    25\n",
       "500    21\n",
       "Name: 0, Length: 498, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "It worked.\n",
    "'''\n",
    "clean_date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1666b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_meses = {\"jan\": \"Jan\",\n",
    "              \"fev\": \"Feb\",\n",
    "              \"mar\": \"Mar\", \n",
    "              \"abr\": \"Apr\", \n",
    "              \"mai\": \"May\", \n",
    "              \"jun\": \"Jun\",\n",
    "              \"jul\": \"Jul\",\n",
    "              \"ago\": \"Aug\", \n",
    "              \"set\": \"Sep\", \n",
    "              \"out\": \"Oct\", \n",
    "              \"nov\": \"Nov\",\n",
    "              \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(mapa_meses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04802706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Sep\n",
       "1      Nov\n",
       "2      May\n",
       "3      Aug\n",
       "4      Nov\n",
       "      ... \n",
       "496    Mar\n",
       "497    May\n",
       "498    Nov\n",
       "499    Apr\n",
       "500    Mar\n",
       "Name: 1, Length: 498, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_date[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44f4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = clean_date.apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "df_limpo['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3df7e",
   "metadata": {},
   "source": [
    "<h1>View Cleaning</h1>\n",
    "<p>Again, cleaning the views using the same old regular expression. No changes here either.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b70ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_11540/2268995852.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d993beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo['views'] = views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c1305",
   "metadata": {},
   "source": [
    "<h1>Creating Views</h1>\n",
    "<p>The process of creating views is the same as before.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7457d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df_limpo.index)\n",
    "y = df['y'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae896c",
   "metadata": {},
   "source": [
    "<h5>Cleaning the date type</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983faaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      851 days\n",
       "1      777 days\n",
       "2      610 days\n",
       "3      507 days\n",
       "4      763 days\n",
       "         ...   \n",
       "496   1037 days\n",
       "497    946 days\n",
       "498    418 days\n",
       "499    617 days\n",
       "500    652 days\n",
       "Name: date, Length: 498, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(\"2021-01-01\") - df_limpo[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8c28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['time_since_pub'] = (pd.to_datetime(\"2021-01-01\") - df_limpo['date']) / np.timedelta64(1, 'D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b32dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    851.0\n",
       "1    777.0\n",
       "2    610.0\n",
       "3    507.0\n",
       "4    763.0\n",
       "Name: time_since_pub, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['time_since_pub'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1de2c",
   "metadata": {},
   "source": [
    "<h5>Cleaning the views</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b236309",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['views'] = df_limpo['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91afae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['views_per_day'] = features['views'] / features['time_since_pub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9926c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['time_since_pub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c8b5e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28028</td>\n",
       "      <td>32.935370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1131</td>\n",
       "      <td>1.455598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1816</td>\n",
       "      <td>2.977049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1171</td>\n",
       "      <td>2.309665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1228</td>\n",
       "      <td>1.609436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   views  views_per_day\n",
       "0  28028      32.935370\n",
       "1   1131       1.455598\n",
       "2   1816       2.977049\n",
       "3   1171       2.309665\n",
       "4   1228       1.609436"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01e455",
   "metadata": {},
   "source": [
    "<h1>Creating some variables to our model</h1>\n",
    "<p>Now we are gonna create some variables to use in our new model. Then, we are going to create the train and test variables, as always.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d7d1455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228, 2), (270, 2), (228,), (270,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < \"2019-04-01\"\n",
    "mask_val = df_limpo['date'] >= \"2019-04-01\"\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c78b9e",
   "metadata": {},
   "source": [
    "<h1>Turn strings into numbers</h1>\n",
    "<p>Our models can only understand numbers, not strings. And the column \"title\" only has words on it. To solve this problem, we can create a matrix wich counts how many times a word appears. Then we can create a column with each word and the counting in each line of dataframe. To do that we use the \"TfidfVectorizer\" library</p>\n",
    "\n",
    "<p>TfidfVectorizer is a library that gives more weight to words that appears too little in all the videos but too much in a single video. The \"min_df\" parameter dictates in how many videos a word must appear at minimum. We can adjust that number at will, but by doing this, it will affect the model's performance.</p>\n",
    "\n",
    "<h5>Sparcity of the matrix</h5>\n",
    "<p>By default, the vectorizer give us a sparse matrix, for optmization purposes. Meaning that we will only store values != 0. This is a way to conserve memory without allocating unnecessary resources to store unnecessary values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf9f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_limpo['title'] = df['watch-title']\n",
    "\n",
    "title_train = df_limpo[mask_train]['title']\n",
    "title_val = df_limpo[mask_val]['title']\n",
    "\n",
    "#Title Bow is a bag of words\n",
    "title_vec = TfidfVectorizer(min_df=2)\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6afb3a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<228x193 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1277 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0149dfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<270x193 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1266 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fdced",
   "metadata": {},
   "source": [
    "<p>We have a matrix of 228 by 193. Meaning, our total matrix space, counting the zeroes is 228*193.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cb537bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 193)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45c32d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<228x193 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1277 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3d822",
   "metadata": {},
   "source": [
    "<p>Almost all the dataframe (97%) is composed of zeroes. In order to preserve memory, we don't need to store the zeroes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3605a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709799109171894"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 1277/(228*193)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d03cae",
   "metadata": {},
   "source": [
    "<h5>Joining some matrices</h5>\n",
    "<p>To join some matrices, we can use the \"hstack\" library from \"scipy.sparse\". There are 2 ways to join matrices. One way is through hstack, another through vstack. The differences between them can be seen down below. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hstack - [1 2]     [3 4]   -> [1 2 3 4] - 1x4\n",
    "\n",
    "vstack - [1 2]     [3 4]   -> [1 2]\n",
    "                              [3 4] - 2x2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6427e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Effectvily joining matrices\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "Xtrain_wtitle = hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = hstack([Xval, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ade29d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228, 195), (270, 195))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle.shape, Xval_wtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131b1b9",
   "metadata": {},
   "source": [
    "<h1>Creating a model with Random Forest</h1>\n",
    "<p>In order to beat the scores in our baseline, now we are going to use the Random Forest algorithm.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06524045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=6,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c381f",
   "metadata": {},
   "source": [
    "<h5>Verifying the results</h5>\n",
    "<p>After the training we are going to analyse the results with the \"roc_auc_score\" and the \"average_precision_score\". </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e6d6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f61c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78a2d3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18367911080129234"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8292ef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5761094224924012"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b8abb",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>\n",
    "<p>We have a higher precision score but a lower auc_roc_score. So, we can not conclude anything. We need both the metrics to be higher than our baseline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958089b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
