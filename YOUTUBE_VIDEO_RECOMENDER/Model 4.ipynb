{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8353c",
   "metadata": {},
   "source": [
    "<h1>Creating a new model</h1>\n",
    "<p>In order to improve even more our baseline, we will create another model and try new things. This process doesn't change much from other models. And if we hit a step wich is different than before, i will just say it. Other than that, i will just follow along.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2229e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import bs4 as bs4\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "pd.set_option(\"max.columns\", 131)\n",
    "\n",
    "#https://strftime.org/\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72a4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels_curso - to_label_2.csv\", index_col=0).dropna(subset=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971c1a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601f98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = pd.DataFrame(index=df.index)\n",
    "df_limpo['title'] = df['watch-title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec9b35",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9555ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].map(lambda x: \"0\"+x[0] if len(x) == 1 else x)\n",
    "#clean_date[1] = clean_date[1].map(lambda x: x[0].upper()+x[1:])\n",
    "\n",
    "mapa_meses = {\"jan\": \"Jan\",\n",
    "              \"fev\": \"Feb\",\n",
    "              \"mar\": \"Mar\", \n",
    "              \"abr\": \"Apr\", \n",
    "              \"mai\": \"May\", \n",
    "              \"jun\": \"Jun\",\n",
    "              \"jul\": \"Jul\",\n",
    "              \"ago\": \"Aug\", \n",
    "              \"set\": \"Sep\", \n",
    "              \"out\": \"Oct\", \n",
    "              \"nov\": \"Nov\",\n",
    "              \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(mapa_meses)\n",
    "\n",
    "clean_date = clean_date.apply(lambda x: \" \".join(x), axis=1)\n",
    "clean_date.head()\n",
    "df_limpo['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cfc5f2",
   "metadata": {},
   "source": [
    "<h1>Cleaning the views</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0fa484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_14136/2939520255.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n",
    "df_limpo['views'] = views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05eeaf",
   "metadata": {},
   "source": [
    "<h1>Creating new features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1437989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df_limpo.index)\n",
    "y = df['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acab58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['time_since_pub'] = (pd.to_datetime(\"2019-12-03\") - df_limpo['date']) / np.timedelta64(1, 'D')\n",
    "features['views'] = df_limpo['views']\n",
    "features['views_per_day'] = features['views'] / features['time_since_pub']\n",
    "features = features.drop(['time_since_pub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca7335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28028</td>\n",
       "      <td>61.464912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1161</td>\n",
       "      <td>21.109091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>141646</td>\n",
       "      <td>809.405714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>325</td>\n",
       "      <td>21.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>61</td>\n",
       "      <td>7.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      views  views_per_day\n",
       "0     28028      61.464912\n",
       "394    1161      21.109091\n",
       "393  141646     809.405714\n",
       "392     325      21.666667\n",
       "391      61       7.625000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd74c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((555, 2), (609, 2), (555,), (609,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < \"2019-04-01\"\n",
    "mask_val = (df_limpo['date'] >= \"2019-04-01\")\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950391b5",
   "metadata": {},
   "source": [
    "<h5>Trying a new parameter for our vetorizer</h5>\n",
    "<p>Now we are trying a new parameter for the vectorizer. The \"ngram_range\". This receives 2 values: the min and maximum words that are gonna be considered as different sets (titles in this case). Meaning that if we have something like ngram_range(1,2), then we will consider every separated word as 1 title and every 2 words together as 1 title. If we use ngram_range(2,2), that means we are only considering use a pair of words as our title.</p> \n",
    "    \n",
    "<p>Some examples can be seen right down below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c7b82fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nintro to machine learning -> intro, to, machine, learning  -> ngram_range=(1,1)  \\nintro to machine learning -> intro, to, machine, learning, intro to, to machine, machine learning -> ngram_range=(1,2)  \\nintro to machine learning -> intro to, to machine, machine learning -> ngram_range=(2,2)  \\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "intro to machine learning -> intro, to, machine, learning  -> ngram_range=(1,1)  \n",
    "intro to machine learning -> intro, to, machine, learning, intro to, to machine, machine learning -> ngram_range=(1,2)  \n",
    "intro to machine learning -> intro to, to machine, machine learning -> ngram_range=(2,2)  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e5d473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "title_train = df_limpo[mask_train]['title']\n",
    "title_val = df_limpo[mask_val]['title']\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=2, ngram_range=(1,4))\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b9b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 1333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e4563",
   "metadata": {},
   "source": [
    "<h1>Mounting the dataframes together</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0556b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "Xtrain_wtitle = hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = hstack([Xval, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c80dc6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((555, 1335), (609, 1335))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle.shape, Xval_wtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53c9a9",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2583ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f775f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=6,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=0, min_samples_leaf=1, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f199f",
   "metadata": {},
   "source": [
    "<h5>Showing some results</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e944293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7cfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f491cf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21042440914051194"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b2e5427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6897446482278705"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702f78c",
   "metadata": {},
   "source": [
    "<h5>Tunning some parameters</h5>\n",
    "<p>Some tunning was made, manually. Those can be seen down below. \n",
    "    But there are way better ways to do that.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a90f642a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nap 0.1887361518270232, auc 0.6766232234475438\\nap 0.1773056089416357, auc 0.66359025771068 - min_samples_leaf=2\\n\\nap 0.17595568029276232, auc 0.6454708969747007 - min_df=1  \\nap 0.17508239417116303, auc 0.650247685321696 - min_df=3  \\nap 0.21140611241061869, auc 0.6785398360559061 - min_df=2, ngram_range=(1,2)  \\nap 0.22228951304206077, auc 0.6914990859232175 - min_df=2, ngram_range=(1,3)  \\nap 0.20564709615419985, auc 0.6848794008374124 - min_df=2, ngram_range=(1,4)  \\n\\n\\nap 0.1834073532858915, auc 0.6716990033614437 - n_estimators=100\\nap 0.1762251704396226, auc 0.6700772542312909 - n_estimators=100, min_samples_leaf=2  \\n\\n\\nRF ap 0.22228951304206077, auc 0.6914990859232175 - min_df=2, ngram_range=(1,3)  \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ap 0.1887361518270232, auc 0.6766232234475438\n",
    "ap 0.1773056089416357, auc 0.66359025771068 - min_samples_leaf=2\n",
    "\n",
    "ap 0.17595568029276232, auc 0.6454708969747007 - min_df=1  \n",
    "ap 0.17508239417116303, auc 0.650247685321696 - min_df=3  \n",
    "ap 0.21140611241061869, auc 0.6785398360559061 - min_df=2, ngram_range=(1,2)  \n",
    "ap 0.22228951304206077, auc 0.6914990859232175 - min_df=2, ngram_range=(1,3)  \n",
    "ap 0.20564709615419985, auc 0.6848794008374124 - min_df=2, ngram_range=(1,4)  \n",
    "\n",
    "\n",
    "ap 0.1834073532858915, auc 0.6716990033614437 - n_estimators=100\n",
    "ap 0.1762251704396226, auc 0.6700772542312909 - n_estimators=100, min_samples_leaf=2  \n",
    "\n",
    "\n",
    "RF ap 0.22228951304206077, auc 0.6914990859232175 - min_df=2, ngram_range=(1,3)  \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be125f9e",
   "metadata": {},
   "source": [
    "<h1>LightGBM</h1>\n",
    "<p>A new algorithm will be tested. The LightGBM is used to have a good performance overall. Let's check that up.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ad96cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b810a67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', n_jobs=6, random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = LGBMClassifier(random_state=0, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8e4e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wagne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\lightgbm\\basic.py:739: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "996dd418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1665181138269886, 0.5684378132924456)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p), roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8a940",
   "metadata": {},
   "source": [
    "<h1>Bayesian Optimization</h1>\n",
    "<p>We chose some parameters for the LightGBM algorithm. But without any criteria whatsoever. We need a better way to  choose the parameters that is going to have the best performance and the best results. To do that, we will use something called Bayesian Optimization. </p>\n",
    "<p>Bayesian Optimization is a way to optimize a model by tuning many parameters. The goal is to find the best metrics possible for our model. We can do that by choosing randomlly the parameters until we meet a pre defined number of steps. We can also make a brute force search, looking for all the possible parameters combinations. This method is extremamelly costy in both time and computational resources. </p>\n",
    "<p>The optimization can also be done in a clever way.  Always looking to the parameters that are improving the model - reaching an optimization point. That is what we are trying to do down below, using a library called \"forest_minimize\".</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afd74539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import forest_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89838e",
   "metadata": {},
   "source": [
    "<p>A function called \"tune_lgbm\" is being created to find the best parameters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b8733f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    \n",
    "    title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    title_bow_train = title_vec.fit_transform(title_train)\n",
    "    title_bow_val = title_vec.transform(title_val)\n",
    "    \n",
    "    Xtrain_wtitle = hstack([Xtrain, title_bow_train])\n",
    "    Xval_wtitle = hstack([Xval, title_bow_val])\n",
    "    \n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                         min_child_samples=min_child_samples, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                         class_weight=\"balanced\", n_jobs=6)\n",
    "    mdl.fit(Xtrain_wtitle, ytrain)\n",
    "    \n",
    "    p = mdl.predict_proba(Xval_wtitle)[:, 1]\n",
    "    \n",
    "    print(roc_auc_score(yval, p))\n",
    "    \n",
    "    return -average_precision_score(yval, p)\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (1,5), # min_df\n",
    "          (1,5)] # ngram_range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7c17f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Version' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_14136/2651575275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The best parameters are gonna be stored in the variable \"res\" in the order specified by the tunning function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune_lgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m160745\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\wagne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\optimizer\\forest.py\u001b[0m in \u001b[0;36mforest_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mskopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdummy_minimize\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m     return base_minimize(func, dimensions, base_estimator,\n\u001b[0m\u001b[0;32m    170\u001b[0m                          \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                          \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_random_starts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wagne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;31m# Optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wagne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36mask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_points\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0msupported_strategies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"cl_min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cl_mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cl_max\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wagne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36m_ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;31m# this will not make a copy of `self.rng` and hence keep advancing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;31m# our random state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wagne\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\space\\space.py\u001b[0m in \u001b[0;36mrvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0msp_version\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'Version' and 'tuple'"
     ]
    }
   ],
   "source": [
    "# The best parameters are gonna be stored in the variable \"res\" in the order specified by the tunning function\n",
    "res = forest_minimize(tune_lgbm, space, random_state=160745, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "038892f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_14136/1542622709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4aec2",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression</h1>\n",
    "<p>Now we are gonna test the Logistic Regression algorith.</p>\n",
    "<p>Logistic regression is a statistical method used to predict the outcome of a dependent variable based on previous observations. It's a type of regression analysis and is a commonly used algorithm for solving binary classification problems.</p>\n",
    "<p>Regression Analysis is a type of predictive modeling technique used to find the relationship between a dependent variable and one or more independent variables.</p>\n",
    "\n",
    "<a href=\"https://learn.g2.com/logistic-regression\">Referência</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2b637cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74e014",
   "metadata": {},
   "source": [
    "<h1>Scalers</h1>\n",
    "<p>In order to make predictions we can't use too large or too small numbers. That's because this is gonna make our model too dependent on this high devious numbers. To make things simpler, we scale our numbers. And there is lots of ways of doing this. \n",
    "Here are some ways: <a href=\"https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#results\">All scaling methods</a></p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad234587",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_wtitle2 = csr_matrix(Xtrain_wtitle.copy())\n",
    "Xval_wtitle2 = csr_matrix(Xval_wtitle.copy())\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "\n",
    "\n",
    "#Xtrain_wtitle2[:, :2] = scaler.fit_transform(Xtrain_wtitle2[:, :2].todense())\n",
    "#Xval_wtitle2[:, :2] = scaler.transform(Xval_wtitle2[:, :2].todense())\n",
    "\n",
    "Xtrain_wtitle2 = scaler.fit_transform(Xtrain_wtitle2)\n",
    "Xval_wtitle2 = scaler.transform(Xval_wtitle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ffa83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 1335)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_wtitle2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88e342dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, n_jobs=6, random_state=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mdl = LogisticRegression(C=0.5,n_jobs=6, random_state=0)\n",
    "mdl.fit(Xtrain_wtitle2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aed4b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9619d8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2162535946903888, 0.6861178274458927)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p), roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff60bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(0.20616279322296893, 0.6606416229285841) - sem tuning, standardscaler\\n\\n(0.20757989629841797, 0.6862357728371764) - sem tuning, maxabsscaler\\n(0.18953863996413214, 0.6741463702305833) - C=10, maxabsscaler\\n\\n(0.21340786207179874, 0.6835525151854692) - C=0.5, maxabsscaler\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "(0.20616279322296893, 0.6606416229285841) - sem tuning, standardscaler\n",
    "\n",
    "(0.20757989629841797, 0.6862357728371764) - sem tuning, maxabsscaler\n",
    "(0.18953863996413214, 0.6741463702305833) - C=10, maxabsscaler\n",
    "\n",
    "(0.21340786207179874, 0.6835525151854692) - C=0.5, maxabsscaler\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867572c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
